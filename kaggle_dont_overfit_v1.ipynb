{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC  \n",
    "import scipy.stats as stats\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867</td>\n",
       "      <td>1.347</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-2.097</td>\n",
       "      <td>1.051</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>1.038</td>\n",
       "      <td>-1.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.081</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.317</td>\n",
       "      <td>1.172</td>\n",
       "      <td>0.352</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-1.695</td>\n",
       "      <td>-1.257</td>\n",
       "      <td>1.359</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>-1.624</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-1.099</td>\n",
       "      <td>-0.936</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-1.222</td>\n",
       "      <td>0.726</td>\n",
       "      <td>1.444</td>\n",
       "      <td>-1.165</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.392</td>\n",
       "      <td>-1.637</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.725</td>\n",
       "      <td>-1.035</td>\n",
       "      <td>0.834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.640</td>\n",
       "      <td>-0.595</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.347</td>\n",
       "      <td>-0.831</td>\n",
       "      <td>0.511</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.594</td>\n",
       "      <td>0.585</td>\n",
       "      <td>1.509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.134</td>\n",
       "      <td>2.415</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-1.006</td>\n",
       "      <td>1.378</td>\n",
       "      <td>1.246</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target      0      1      2      3      4      5      6      7  ...    \\\n",
       "0   0     1.0 -0.098  2.165  0.681 -0.614  1.309 -0.455 -0.236  0.276  ...     \n",
       "1   1     0.0  1.081 -0.973 -0.383  0.326 -0.428  0.317  1.172  0.352  ...     \n",
       "2   2     1.0 -0.523 -0.089 -0.348  0.148 -0.022  0.404 -0.023 -0.172  ...     \n",
       "3   3     1.0  0.067 -0.021  0.392 -1.637 -0.446 -0.725 -1.035  0.834  ...     \n",
       "4   4     1.0  2.347 -0.831  0.511 -0.021  1.225  1.594  0.585  1.509  ...     \n",
       "\n",
       "     290    291    292    293    294    295    296    297    298    299  \n",
       "0  0.867  1.347  0.504 -0.649  0.672 -2.097  1.051 -0.414  1.038 -1.065  \n",
       "1 -0.165 -1.695 -1.257  1.359 -0.808 -1.624 -0.458 -1.099 -0.936  0.973  \n",
       "2  0.013  0.263 -1.222  0.726  1.444 -1.165 -1.544  0.004  0.800 -1.211  \n",
       "3 -0.404  0.640 -0.595 -0.966  0.900  0.467 -0.562 -0.254 -0.533  0.238  \n",
       "4  0.898  0.134  2.415 -0.996 -1.006  1.378  1.246  1.478  0.428  0.253  \n",
       "\n",
       "[5 rows x 302 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = pd.read_csv(\"C:/Users/mruna/Desktop/Kaggle/Dont_overfit/train.csv\")\n",
    "train_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>124.500000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.023292</td>\n",
       "      <td>-0.026872</td>\n",
       "      <td>0.167404</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>0.032052</td>\n",
       "      <td>0.078412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044652</td>\n",
       "      <td>0.126344</td>\n",
       "      <td>0.018436</td>\n",
       "      <td>-0.012092</td>\n",
       "      <td>-0.065720</td>\n",
       "      <td>-0.106112</td>\n",
       "      <td>0.046472</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.009372</td>\n",
       "      <td>-0.128952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>72.312977</td>\n",
       "      <td>0.480963</td>\n",
       "      <td>0.998354</td>\n",
       "      <td>1.009314</td>\n",
       "      <td>1.021709</td>\n",
       "      <td>1.011751</td>\n",
       "      <td>1.035411</td>\n",
       "      <td>0.955700</td>\n",
       "      <td>1.006657</td>\n",
       "      <td>0.939731</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011416</td>\n",
       "      <td>0.972567</td>\n",
       "      <td>0.954229</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>1.057414</td>\n",
       "      <td>1.038389</td>\n",
       "      <td>0.967661</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>1.008099</td>\n",
       "      <td>0.971219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.319000</td>\n",
       "      <td>-2.931000</td>\n",
       "      <td>-2.477000</td>\n",
       "      <td>-2.359000</td>\n",
       "      <td>-2.566000</td>\n",
       "      <td>-2.845000</td>\n",
       "      <td>-2.976000</td>\n",
       "      <td>-3.444000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.804000</td>\n",
       "      <td>-2.443000</td>\n",
       "      <td>-2.757000</td>\n",
       "      <td>-2.466000</td>\n",
       "      <td>-3.287000</td>\n",
       "      <td>-3.072000</td>\n",
       "      <td>-2.634000</td>\n",
       "      <td>-2.776000</td>\n",
       "      <td>-3.211000</td>\n",
       "      <td>-3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>62.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.644750</td>\n",
       "      <td>-0.739750</td>\n",
       "      <td>-0.425250</td>\n",
       "      <td>-0.686500</td>\n",
       "      <td>-0.659000</td>\n",
       "      <td>-0.643750</td>\n",
       "      <td>-0.675000</td>\n",
       "      <td>-0.550750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.617000</td>\n",
       "      <td>-0.510500</td>\n",
       "      <td>-0.535750</td>\n",
       "      <td>-0.657000</td>\n",
       "      <td>-0.818500</td>\n",
       "      <td>-0.821000</td>\n",
       "      <td>-0.605500</td>\n",
       "      <td>-0.751250</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>-0.754250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>124.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015500</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>-0.016500</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>-0.009000</td>\n",
       "      <td>-0.079500</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>-0.009000</td>\n",
       "      <td>-0.132500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>186.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.620750</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.660500</td>\n",
       "      <td>0.783250</td>\n",
       "      <td>0.766250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797250</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.631500</td>\n",
       "      <td>0.650250</td>\n",
       "      <td>0.739500</td>\n",
       "      <td>0.493000</td>\n",
       "      <td>0.683000</td>\n",
       "      <td>0.794250</td>\n",
       "      <td>0.654250</td>\n",
       "      <td>0.503250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>249.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.567000</td>\n",
       "      <td>2.419000</td>\n",
       "      <td>3.392000</td>\n",
       "      <td>2.771000</td>\n",
       "      <td>2.901000</td>\n",
       "      <td>2.793000</td>\n",
       "      <td>2.546000</td>\n",
       "      <td>2.846000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.865000</td>\n",
       "      <td>2.801000</td>\n",
       "      <td>2.736000</td>\n",
       "      <td>2.596000</td>\n",
       "      <td>2.226000</td>\n",
       "      <td>3.131000</td>\n",
       "      <td>3.236000</td>\n",
       "      <td>2.626000</td>\n",
       "      <td>3.530000</td>\n",
       "      <td>2.771000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      target           0           1           2           3  \\\n",
       "count  250.000000  250.000000  250.000000  250.000000  250.000000  250.000000   \n",
       "mean   124.500000    0.640000    0.023292   -0.026872    0.167404    0.001904   \n",
       "std     72.312977    0.480963    0.998354    1.009314    1.021709    1.011751   \n",
       "min      0.000000    0.000000   -2.319000   -2.931000   -2.477000   -2.359000   \n",
       "25%     62.250000    0.000000   -0.644750   -0.739750   -0.425250   -0.686500   \n",
       "50%    124.500000    1.000000   -0.015500    0.057000    0.184000   -0.016500   \n",
       "75%    186.750000    1.000000    0.677000    0.620750    0.805000    0.720000   \n",
       "max    249.000000    1.000000    2.567000    2.419000    3.392000    2.771000   \n",
       "\n",
       "                4           5           6           7     ...             290  \\\n",
       "count  250.000000  250.000000  250.000000  250.000000     ...      250.000000   \n",
       "mean     0.001588   -0.007304    0.032052    0.078412     ...        0.044652   \n",
       "std      1.035411    0.955700    1.006657    0.939731     ...        1.011416   \n",
       "min     -2.566000   -2.845000   -2.976000   -3.444000     ...       -2.804000   \n",
       "25%     -0.659000   -0.643750   -0.675000   -0.550750     ...       -0.617000   \n",
       "50%     -0.023000    0.037500    0.060500    0.183500     ...        0.067500   \n",
       "75%      0.735000    0.660500    0.783250    0.766250     ...        0.797250   \n",
       "max      2.901000    2.793000    2.546000    2.846000     ...        2.865000   \n",
       "\n",
       "              291         292         293         294         295         296  \\\n",
       "count  250.000000  250.000000  250.000000  250.000000  250.000000  250.000000   \n",
       "mean     0.126344    0.018436   -0.012092   -0.065720   -0.106112    0.046472   \n",
       "std      0.972567    0.954229    0.960630    1.057414    1.038389    0.967661   \n",
       "min     -2.443000   -2.757000   -2.466000   -3.287000   -3.072000   -2.634000   \n",
       "25%     -0.510500   -0.535750   -0.657000   -0.818500   -0.821000   -0.605500   \n",
       "50%      0.091000    0.057500   -0.021000   -0.009000   -0.079500    0.009500   \n",
       "75%      0.804250    0.631500    0.650250    0.739500    0.493000    0.683000   \n",
       "max      2.801000    2.736000    2.596000    2.226000    3.131000    3.236000   \n",
       "\n",
       "              297         298         299  \n",
       "count  250.000000  250.000000  250.000000  \n",
       "mean     0.006452    0.009372   -0.128952  \n",
       "std      0.998984    1.008099    0.971219  \n",
       "min     -2.776000   -3.211000   -3.500000  \n",
       "25%     -0.751250   -0.550000   -0.754250  \n",
       "50%      0.005500   -0.009000   -0.132500  \n",
       "75%      0.794250    0.654250    0.503250  \n",
       "max      2.626000    3.530000    2.771000  \n",
       "\n",
       "[8 rows x 302 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6  \\\n",
      "0    1.000000 -0.003871 -0.010487 -0.047819  0.013967  0.070091 -0.022537   \n",
      "1   -0.003871  1.000000  0.013573 -0.018884  0.086743 -0.028023 -0.032914   \n",
      "2   -0.010487  0.013573  1.000000 -0.031620  0.088980 -0.050191  0.024674   \n",
      "3   -0.047819 -0.018884 -0.031620  1.000000  0.025255  0.172058  0.157954   \n",
      "4    0.013967  0.086743  0.088980  0.025255  1.000000 -0.013072 -0.030131   \n",
      "5    0.070091 -0.028023 -0.050191  0.172058 -0.013072  1.000000 -0.002426   \n",
      "6   -0.022537 -0.032914  0.024674  0.157954 -0.030131 -0.002426  1.000000   \n",
      "7    0.002832 -0.066416  0.035260 -0.018158  0.037315  0.087932 -0.035602   \n",
      "8   -0.060031 -0.027201 -0.000094  0.058736 -0.186559  0.013425 -0.043699   \n",
      "9   -0.052356  0.035512  0.009949 -0.087360  0.031577  0.055556 -0.014648   \n",
      "10   0.059263  0.020358  0.015158  0.095171 -0.008063  0.022024  0.139278   \n",
      "11  -0.014094  0.003761 -0.029568  0.007442  0.007968 -0.010794 -0.199293   \n",
      "12  -0.060538  0.027094  0.097398  0.045094  0.132275  0.040214 -0.077901   \n",
      "13   0.049368 -0.111360 -0.073799 -0.041555 -0.054940  0.053074 -0.028456   \n",
      "14  -0.017255 -0.030637 -0.000265 -0.031459  0.000499  0.000897 -0.018627   \n",
      "15  -0.047828 -0.084130  0.033148 -0.000283 -0.090977  0.084578  0.045245   \n",
      "16  -0.031047  0.023147 -0.054838 -0.065051  0.007262  0.051093  0.015405   \n",
      "17   0.013264 -0.115217 -0.019571 -0.025095 -0.096988 -0.131270  0.030455   \n",
      "18  -0.043416  0.065643 -0.078429  0.022526 -0.081156 -0.088878 -0.032627   \n",
      "19  -0.005945  0.051571 -0.015709 -0.069960 -0.058581  0.062958 -0.019670   \n",
      "20  -0.000825  0.055748  0.007613  0.001301  0.052647  0.037632 -0.090969   \n",
      "21   0.030775 -0.084465  0.031090 -0.045099  0.003676  0.099301 -0.057341   \n",
      "22  -0.031150  0.039373 -0.018003  0.040782  0.109518  0.041747 -0.068222   \n",
      "23  -0.055822 -0.033250  0.115579 -0.000773  0.066811 -0.040516 -0.020787   \n",
      "24  -0.030686  0.069004  0.002037 -0.058211  0.008885  0.027247  0.028545   \n",
      "25  -0.019718  0.105601  0.081629 -0.036736  0.077538 -0.109747  0.020797   \n",
      "26  -0.005644  0.011806  0.063708  0.081253 -0.040955  0.063418  0.116898   \n",
      "27   0.027852 -0.031546  0.135030  0.094281 -0.083632  0.035137  0.024613   \n",
      "28   0.035622 -0.134291  0.021411 -0.072850 -0.064853 -0.032448  0.041625   \n",
      "29  -0.008151 -0.058598 -0.066181  0.055668  0.045321  0.007844 -0.096269   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "270 -0.013818  0.026795 -0.125342  0.002538 -0.026924 -0.023682  0.024495   \n",
      "271 -0.022710 -0.020315  0.074181  0.103659  0.116022  0.039628  0.039890   \n",
      "272  0.007584 -0.006171 -0.160163  0.134583  0.032491  0.033679 -0.003165   \n",
      "273 -0.020473 -0.146324 -0.031669  0.030648 -0.023327 -0.064961 -0.086702   \n",
      "274  0.075098 -0.015831  0.021250 -0.048846 -0.018470 -0.062320  0.066603   \n",
      "275  0.054375 -0.049975  0.046178  0.068337 -0.013100  0.003703  0.036888   \n",
      "276 -0.028977 -0.031120  0.040289 -0.086846  0.021474  0.001804 -0.013716   \n",
      "277 -0.041199  0.070214 -0.027123  0.000727  0.077814 -0.019020 -0.082993   \n",
      "278  0.022243 -0.016917 -0.073515 -0.058637 -0.047860 -0.023463 -0.056725   \n",
      "279 -0.102684  0.032828 -0.012218  0.000049  0.016064 -0.025639  0.094583   \n",
      "280 -0.024006  0.098995 -0.036694  0.010798 -0.040175 -0.003489 -0.021445   \n",
      "281  0.037312  0.119581  0.080078 -0.029653 -0.021688 -0.044853 -0.019179   \n",
      "282  0.135009 -0.096928 -0.010019 -0.001238  0.031517 -0.047173  0.067782   \n",
      "283  0.029303  0.066795 -0.122932 -0.093418 -0.054424  0.082530 -0.071567   \n",
      "284  0.031001 -0.047459  0.059758  0.015668 -0.010751 -0.052762 -0.050025   \n",
      "285  0.033796  0.058864 -0.066441 -0.023216 -0.048290  0.042365  0.051614   \n",
      "286  0.164564  0.041791  0.003450  0.042055 -0.093875  0.090503  0.118022   \n",
      "287  0.012922  0.096635  0.073678  0.030620  0.094702  0.015096 -0.135902   \n",
      "288 -0.027903 -0.131251 -0.090725  0.048973  0.011539  0.020335  0.013871   \n",
      "289  0.034457 -0.070546  0.046566 -0.028037  0.083630  0.102683 -0.143277   \n",
      "290 -0.023230 -0.006300 -0.111172 -0.114505  0.096056  0.027638 -0.026921   \n",
      "291  0.053416 -0.077365 -0.027842  0.029415  0.056339 -0.095449  0.133380   \n",
      "292 -0.143668 -0.021583 -0.013653  0.129069 -0.091165  0.002309 -0.024050   \n",
      "293 -0.007530 -0.054171 -0.009691  0.096159  0.073098  0.049059 -0.012804   \n",
      "294 -0.060824 -0.046174 -0.051292 -0.027793  0.158532 -0.032129  0.084606   \n",
      "295 -0.024839  0.042820 -0.028690 -0.005016 -0.050318  0.026868 -0.023192   \n",
      "296 -0.051288 -0.127499 -0.071835  0.034551 -0.030017  0.070294  0.036903   \n",
      "297  0.029143  0.065883  0.069395  0.089963  0.029747  0.069243  0.037912   \n",
      "298  0.065951  0.055470  0.083946 -0.066438 -0.008517 -0.048009  0.171640   \n",
      "299  0.038523 -0.056612  0.025507 -0.010770 -0.040654 -0.084178 -0.004655   \n",
      "\n",
      "            7         8         9    ...          290       291       292  \\\n",
      "0    0.002832 -0.060031 -0.052356    ...    -0.023230  0.053416 -0.143668   \n",
      "1   -0.066416 -0.027201  0.035512    ...    -0.006300 -0.077365 -0.021583   \n",
      "2    0.035260 -0.000094  0.009949    ...    -0.111172 -0.027842 -0.013653   \n",
      "3   -0.018158  0.058736 -0.087360    ...    -0.114505  0.029415  0.129069   \n",
      "4    0.037315 -0.186559  0.031577    ...     0.096056  0.056339 -0.091165   \n",
      "5    0.087932  0.013425  0.055556    ...     0.027638 -0.095449  0.002309   \n",
      "6   -0.035602 -0.043699 -0.014648    ...    -0.026921  0.133380 -0.024050   \n",
      "7    1.000000  0.016259 -0.001542    ...     0.002158  0.109255 -0.010870   \n",
      "8    0.016259  1.000000  0.059123    ...    -0.081837 -0.035636 -0.008774   \n",
      "9   -0.001542  0.059123  1.000000    ...     0.118215  0.018054  0.068017   \n",
      "10  -0.072135 -0.051984 -0.066612    ...     0.041851 -0.090508 -0.066538   \n",
      "11   0.000696  0.027498  0.048126    ...    -0.016465 -0.074872  0.048479   \n",
      "12  -0.029012 -0.022826  0.093749    ...    -0.044404  0.060939  0.085301   \n",
      "13  -0.129851 -0.073796  0.087873    ...     0.067172 -0.046984 -0.039332   \n",
      "14   0.003211 -0.041600  0.011040    ...     0.050299 -0.062841 -0.033369   \n",
      "15   0.014177 -0.093867 -0.098303    ...    -0.020125  0.041200  0.016527   \n",
      "16   0.019315 -0.082160 -0.047054    ...    -0.047543 -0.004746 -0.077549   \n",
      "17   0.039841  0.034296  0.039255    ...     0.058518 -0.067853 -0.067064   \n",
      "18  -0.064447 -0.019739 -0.063121    ...    -0.002533  0.035025  0.008584   \n",
      "19   0.066830  0.045290 -0.094595    ...    -0.063456 -0.022331  0.028766   \n",
      "20  -0.037427  0.060797  0.066107    ...    -0.057285 -0.029771  0.066776   \n",
      "21   0.058795 -0.016320 -0.038130    ...     0.080430  0.048942 -0.049956   \n",
      "22  -0.128597  0.029398 -0.084042    ...     0.096401 -0.163088  0.075764   \n",
      "23   0.001874  0.015994  0.003930    ...    -0.010177 -0.059642  0.053468   \n",
      "24   0.020165 -0.091723  0.073740    ...     0.105075 -0.015667  0.020669   \n",
      "25  -0.073241 -0.026322  0.004869    ...     0.000259  0.023866  0.034298   \n",
      "26   0.029705  0.025675  0.031273    ...     0.019259 -0.031011 -0.007975   \n",
      "27   0.016562  0.003313 -0.044160    ...    -0.079914  0.022919  0.121734   \n",
      "28  -0.022672 -0.060709  0.030479    ...     0.086177  0.056256 -0.042673   \n",
      "29   0.074185 -0.028484 -0.086451    ...     0.016580 -0.050236 -0.015755   \n",
      "..        ...       ...       ...    ...          ...       ...       ...   \n",
      "270 -0.085310  0.029798  0.091478    ...    -0.060298 -0.004411  0.076581   \n",
      "271 -0.047192 -0.026331 -0.024132    ...    -0.008536  0.016448  0.027192   \n",
      "272 -0.029143  0.023825  0.095942    ...     0.093476 -0.010894 -0.025662   \n",
      "273 -0.032813 -0.058072  0.002427    ...     0.026530 -0.088661  0.069209   \n",
      "274  0.004536 -0.084231 -0.004351    ...     0.048766 -0.020406  0.059892   \n",
      "275  0.076550 -0.022534 -0.209210    ...    -0.043427  0.035012 -0.065120   \n",
      "276 -0.099319  0.015097  0.061177    ...     0.011443 -0.025595  0.048191   \n",
      "277 -0.004380 -0.068849  0.005829    ...     0.122938 -0.035489  0.069662   \n",
      "278 -0.037637  0.035750 -0.001927    ...     0.126097 -0.060095 -0.052067   \n",
      "279  0.105528  0.031182 -0.104338    ...     0.028292  0.014443 -0.032497   \n",
      "280 -0.009275 -0.028809 -0.046256    ...     0.041386 -0.038085  0.006747   \n",
      "281 -0.093149 -0.008964  0.064582    ...    -0.087108  0.003421  0.062770   \n",
      "282  0.038228 -0.127083  0.046999    ...     0.018572  0.027043  0.012581   \n",
      "283  0.042598 -0.008289  0.031858    ...    -0.037522 -0.071252  0.129363   \n",
      "284 -0.011766 -0.033104 -0.007260    ...    -0.041029  0.030379  0.029664   \n",
      "285  0.026825  0.039401  0.116915    ...    -0.009558  0.051828  0.028306   \n",
      "286  0.031797 -0.006337  0.070715    ...    -0.022406  0.066551 -0.028410   \n",
      "287  0.065175  0.121365  0.032133    ...    -0.012988 -0.055725 -0.119592   \n",
      "288 -0.068548  0.004411  0.048638    ...     0.039070  0.052562 -0.083373   \n",
      "289  0.071279  0.028900  0.069416    ...     0.045336  0.035585  0.126121   \n",
      "290  0.002158 -0.081837  0.118215    ...     1.000000 -0.080239 -0.020013   \n",
      "291  0.109255 -0.035636  0.018054    ...    -0.080239  1.000000 -0.114165   \n",
      "292 -0.010870 -0.008774  0.068017    ...    -0.020013 -0.114165  1.000000   \n",
      "293  0.010266  0.027022  0.034661    ...     0.065859  0.022781  0.027094   \n",
      "294  0.071022 -0.008862  0.091779    ...    -0.161654  0.040141 -0.124483   \n",
      "295  0.032648  0.017297  0.096561    ...    -0.030738 -0.020251  0.015083   \n",
      "296 -0.006235 -0.071254 -0.041897    ...     0.016047  0.042079 -0.045879   \n",
      "297  0.014628  0.009224 -0.112156    ...     0.048496  0.066474 -0.025382   \n",
      "298 -0.031094 -0.000516 -0.005721    ...    -0.125556  0.087400  0.008096   \n",
      "299 -0.122393  0.011950  0.005209    ...     0.082621  0.017763  0.126105   \n",
      "\n",
      "          293       294       295       296       297       298       299  \n",
      "0   -0.007530 -0.060824 -0.024839 -0.051288  0.029143  0.065951  0.038523  \n",
      "1   -0.054171 -0.046174  0.042820 -0.127499  0.065883  0.055470 -0.056612  \n",
      "2   -0.009691 -0.051292 -0.028690 -0.071835  0.069395  0.083946  0.025507  \n",
      "3    0.096159 -0.027793 -0.005016  0.034551  0.089963 -0.066438 -0.010770  \n",
      "4    0.073098  0.158532 -0.050318 -0.030017  0.029747 -0.008517 -0.040654  \n",
      "5    0.049059 -0.032129  0.026868  0.070294  0.069243 -0.048009 -0.084178  \n",
      "6   -0.012804  0.084606 -0.023192  0.036903  0.037912  0.171640 -0.004655  \n",
      "7    0.010266  0.071022  0.032648 -0.006235  0.014628 -0.031094 -0.122393  \n",
      "8    0.027022 -0.008862  0.017297 -0.071254  0.009224 -0.000516  0.011950  \n",
      "9    0.034661  0.091779  0.096561 -0.041897 -0.112156 -0.005721  0.005209  \n",
      "10  -0.061096 -0.022770  0.004286  0.012922 -0.096935 -0.027523  0.089395  \n",
      "11  -0.080823 -0.011480  0.029916  0.021926 -0.091752 -0.107691  0.056845  \n",
      "12   0.091656  0.018026  0.000463  0.095595 -0.033143 -0.122686  0.027726  \n",
      "13  -0.020716 -0.039562 -0.062818 -0.043391  0.064835 -0.047400  0.000047  \n",
      "14  -0.008123  0.085024  0.025472  0.019281 -0.096848 -0.058028 -0.021498  \n",
      "15   0.080148 -0.067548 -0.058256  0.079084  0.057779  0.021571  0.000667  \n",
      "16   0.012209  0.101772 -0.033328  0.062210 -0.032590 -0.002240 -0.022099  \n",
      "17   0.047982  0.034879 -0.122605 -0.000236  0.053383  0.068385 -0.111602  \n",
      "18   0.124090  0.008737 -0.005406 -0.099695  0.094738 -0.026347  0.059311  \n",
      "19  -0.051663 -0.005981  0.002869 -0.031731  0.098549  0.044596 -0.090319  \n",
      "20  -0.078849  0.125156  0.107947  0.012653  0.027744 -0.049494  0.080048  \n",
      "21  -0.079083 -0.010715 -0.045315 -0.091541 -0.005069 -0.001075  0.002890  \n",
      "22  -0.013203 -0.054997 -0.003361  0.001706  0.060292 -0.037747 -0.050302  \n",
      "23   0.001489 -0.032424  0.009173 -0.022030 -0.012929 -0.013223 -0.068532  \n",
      "24   0.008645  0.033071  0.036107 -0.115851  0.016726 -0.080493 -0.066220  \n",
      "25   0.006116  0.093629  0.067894  0.002066  0.066989 -0.017905  0.110874  \n",
      "26   0.046786  0.004116  0.072794 -0.016036 -0.019523  0.056156  0.021063  \n",
      "27   0.067409  0.016727  0.040597  0.013379 -0.041923 -0.016833  0.107508  \n",
      "28   0.090732 -0.057705 -0.004402 -0.094865 -0.008893  0.010796 -0.020644  \n",
      "29   0.131867 -0.030125 -0.022230 -0.009884  0.161778 -0.141259  0.092846  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "270  0.075086 -0.056955 -0.065618 -0.036337 -0.034799 -0.030726  0.026477  \n",
      "271 -0.034761 -0.041243  0.024534  0.084293  0.001520 -0.013832  0.102211  \n",
      "272 -0.076839 -0.007824 -0.023935 -0.007085  0.098548 -0.060075  0.042014  \n",
      "273 -0.078902 -0.032598 -0.026823 -0.044852  0.020186 -0.008378 -0.040816  \n",
      "274  0.015857 -0.073589  0.046715 -0.128732 -0.063394 -0.029994  0.065657  \n",
      "275 -0.077779 -0.065888 -0.064713 -0.054901  0.098359  0.084593  0.024700  \n",
      "276  0.025829 -0.023381  0.071940  0.030464 -0.031393 -0.101621  0.157711  \n",
      "277  0.041885 -0.035982  0.064799 -0.002316 -0.000300 -0.048212  0.009138  \n",
      "278  0.062113 -0.047016 -0.036317 -0.080538 -0.063531  0.042847  0.087687  \n",
      "279 -0.087180 -0.027039 -0.017401  0.048129  0.101069  0.095338 -0.091398  \n",
      "280 -0.045962  0.006860  0.001940  0.061356  0.015178  0.021407 -0.023283  \n",
      "281 -0.029372  0.037314 -0.020929 -0.058629  0.057701  0.009097 -0.062859  \n",
      "282  0.120003  0.064526 -0.041584 -0.025202  0.051016  0.005093  0.036934  \n",
      "283  0.026577  0.068396 -0.028941 -0.054329 -0.043626 -0.105624 -0.023983  \n",
      "284  0.085798 -0.053926  0.085140 -0.036471 -0.020147  0.024573  0.022451  \n",
      "285 -0.051694 -0.111162 -0.021471 -0.011472 -0.127372 -0.028709  0.050203  \n",
      "286 -0.048638 -0.022079  0.000373 -0.022548  0.011568 -0.015270  0.037285  \n",
      "287 -0.069974 -0.017616  0.070608 -0.073599 -0.057366  0.029770 -0.069244  \n",
      "288  0.077909 -0.030012 -0.154858  0.005955 -0.046789  0.129112  0.071017  \n",
      "289  0.041402  0.016806 -0.068796 -0.092074  0.076721 -0.115568  0.001902  \n",
      "290  0.065859 -0.161654 -0.030738  0.016047  0.048496 -0.125556  0.082621  \n",
      "291  0.022781  0.040141 -0.020251  0.042079  0.066474  0.087400  0.017763  \n",
      "292  0.027094 -0.124483  0.015083 -0.045879 -0.025382  0.008096  0.126105  \n",
      "293  1.000000 -0.005332 -0.139025 -0.011766  0.021148 -0.005422  0.012255  \n",
      "294 -0.005332  1.000000 -0.015920  0.125693 -0.103255 -0.063242 -0.081196  \n",
      "295 -0.139025 -0.015920  1.000000 -0.072721 -0.036572 -0.034341  0.097052  \n",
      "296 -0.011766  0.125693 -0.072721  1.000000 -0.002007  0.056297  0.040264  \n",
      "297  0.021148 -0.103255 -0.036572 -0.002007  1.000000  0.039793 -0.141078  \n",
      "298 -0.005422 -0.063242 -0.034341  0.056297  0.039793  1.000000 -0.092017  \n",
      "299  0.012255 -0.081196  0.097052  0.040264 -0.141078 -0.092017  1.000000  \n",
      "\n",
      "[300 rows x 300 columns]\n"
     ]
    }
   ],
   "source": [
    "train_file_corr = train_file.drop(['id', 'target'], axis = 1).corr()\n",
    "print(train_file_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013573</td>\n",
       "      <td>-0.018884</td>\n",
       "      <td>0.086743</td>\n",
       "      <td>-0.028023</td>\n",
       "      <td>-0.032914</td>\n",
       "      <td>-0.066416</td>\n",
       "      <td>-0.027201</td>\n",
       "      <td>0.035512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0063</td>\n",
       "      <td>-0.077365</td>\n",
       "      <td>-0.021583</td>\n",
       "      <td>-0.054171</td>\n",
       "      <td>-0.046174</td>\n",
       "      <td>0.04282</td>\n",
       "      <td>-0.127499</td>\n",
       "      <td>0.065883</td>\n",
       "      <td>0.05547</td>\n",
       "      <td>-0.056612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1         2         3         4         5         6         7  \\\n",
       "1 -0.003871  1.0  0.013573 -0.018884  0.086743 -0.028023 -0.032914 -0.066416   \n",
       "\n",
       "          8         9    ...        290       291       292       293  \\\n",
       "1 -0.027201  0.035512    ...    -0.0063 -0.077365 -0.021583 -0.054171   \n",
       "\n",
       "        294      295       296       297      298       299  \n",
       "1 -0.046174  0.04282 -0.127499  0.065883  0.05547 -0.056612  \n",
       "\n",
       "[1 rows x 300 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_corr[train_file_corr['1'] >= 0.5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.098</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.276</td>\n",
       "      <td>-2.246</td>\n",
       "      <td>1.825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867</td>\n",
       "      <td>1.347</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-2.097</td>\n",
       "      <td>1.051</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>1.038</td>\n",
       "      <td>-1.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.081</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.317</td>\n",
       "      <td>1.172</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-1.695</td>\n",
       "      <td>-1.257</td>\n",
       "      <td>1.359</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>-1.624</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-1.099</td>\n",
       "      <td>-0.936</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-1.222</td>\n",
       "      <td>0.726</td>\n",
       "      <td>1.444</td>\n",
       "      <td>-1.165</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.392</td>\n",
       "      <td>-1.637</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.725</td>\n",
       "      <td>-1.035</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.640</td>\n",
       "      <td>-0.595</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.347</td>\n",
       "      <td>-0.831</td>\n",
       "      <td>0.511</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.594</td>\n",
       "      <td>0.585</td>\n",
       "      <td>1.509</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>2.198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.134</td>\n",
       "      <td>2.415</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-1.006</td>\n",
       "      <td>1.378</td>\n",
       "      <td>1.246</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9  \\\n",
       "0 -0.098  2.165  0.681 -0.614  1.309 -0.455 -0.236  0.276 -2.246  1.825   \n",
       "1  1.081 -0.973 -0.383  0.326 -0.428  0.317  1.172  0.352  0.004 -0.291   \n",
       "2 -0.523 -0.089 -0.348  0.148 -0.022  0.404 -0.023 -0.172  0.137  0.183   \n",
       "3  0.067 -0.021  0.392 -1.637 -0.446 -0.725 -1.035  0.834  0.503  0.274   \n",
       "4  2.347 -0.831  0.511 -0.021  1.225  1.594  0.585  1.509 -0.012  2.198   \n",
       "\n",
       "   ...      290    291    292    293    294    295    296    297    298    299  \n",
       "0  ...    0.867  1.347  0.504 -0.649  0.672 -2.097  1.051 -0.414  1.038 -1.065  \n",
       "1  ...   -0.165 -1.695 -1.257  1.359 -0.808 -1.624 -0.458 -1.099 -0.936  0.973  \n",
       "2  ...    0.013  0.263 -1.222  0.726  1.444 -1.165 -1.544  0.004  0.800 -1.211  \n",
       "3  ...   -0.404  0.640 -0.595 -0.966  0.900  0.467 -0.562 -0.254 -0.533  0.238  \n",
       "4  ...    0.898  0.134  2.415 -0.996 -1.006  1.378  1.246  1.478  0.428  0.253  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_file['target']\n",
    "drops = ['id', 'target']\n",
    "X = train_file\n",
    "X.drop(drops, inplace=True, axis=1)\n",
    "X.head()\n",
    "\n",
    "#vif = pd.DataFrame()\n",
    "#vif[\"features\"] = train_file.columns\n",
    "#vif[\"vif_score\"] = [variance_inflation_factor(train_file.values, i) for i in range(train_file.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True  True  True False  True  True  True False  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True False  True  True  True\n",
      "  True False  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True False  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True False  True  True  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True False  True  True  True False  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True]\n",
      "[ 1  1 11  1  1  1  4  1  1  1  6  1  8  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1 14  1  1  1  1  1  1  1  1  1  1  1 16  1  1  1  1  1  1  1  1\n",
      " 25  1  1  1  1  1  1  1  1  1  1  1  1 18  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  3  1  1  1  1  5  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1 21  1 26  1  1  1  1  1  1  1  1  1  1  1  1  1 23  1  1  1\n",
      "  2  1  1  1  1  1  1  1  1  1  1  1  1  1 20  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1 24  1  1  1  1  1  1  1  1  1  1  1  1 22  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  9  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1 13  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1 19  1  1  1  1  1  1  1  1  1  1  1  1 15  1  1  1 12  1  1  1\n",
      "  1  1  1  1  1  1 17  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 10  1\n",
      "  1  1  1  1  1  1  1  1  1  7  1  1]\n"
     ]
    }
   ],
   "source": [
    "# recursive feature elimination\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "# create the RFE model for the svm classifier \n",
    "# and select attributes\n",
    "rfe = RFE(logreg, 275)\n",
    "rfe1 = rfe.fit(X, y)\n",
    "# print summaries for the selection of attributes\n",
    "print(rfe1.support_)\n",
    "print(rfe1.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '3' '4' '5' '7' '8' '9' '11' '13' '14' '15' '16' '17' '18' '19'\n",
      " '20' '21' '22' '23' '24' '25' '26' '28' '29' '30' '31' '32' '33' '34'\n",
      " '35' '36' '37' '38' '40' '41' '42' '43' '44' '45' '46' '47' '49' '50'\n",
      " '51' '52' '53' '54' '55' '56' '57' '58' '59' '60' '62' '63' '64' '65'\n",
      " '66' '67' '68' '69' '70' '71' '72' '73' '74' '75' '76' '77' '78' '79'\n",
      " '80' '81' '82' '83' '84' '85' '86' '87' '88' '89' '90' '91' '92' '93'\n",
      " '94' '95' '96' '97' '98' '99' '100' '101' '102' '103' '105' '106' '107'\n",
      " '108' '110' '111' '112' '113' '114' '115' '116' '117' '118' '119' '120'\n",
      " '121' '122' '123' '125' '127' '128' '129' '130' '131' '132' '133' '134'\n",
      " '135' '136' '137' '138' '139' '141' '142' '143' '145' '146' '147' '148'\n",
      " '149' '150' '151' '152' '153' '154' '155' '156' '157' '159' '160' '161'\n",
      " '162' '163' '164' '165' '166' '167' '168' '169' '170' '171' '172' '174'\n",
      " '175' '176' '177' '178' '179' '180' '181' '182' '183' '184' '185' '187'\n",
      " '188' '189' '190' '191' '192' '193' '194' '195' '196' '197' '198' '199'\n",
      " '200' '201' '202' '203' '204' '205' '206' '207' '208' '209' '211' '212'\n",
      " '213' '214' '215' '216' '217' '218' '219' '220' '221' '222' '224' '225'\n",
      " '226' '227' '228' '229' '230' '231' '232' '233' '234' '235' '236' '237'\n",
      " '238' '239' '240' '241' '242' '244' '245' '246' '247' '248' '249' '250'\n",
      " '251' '252' '253' '254' '255' '257' '258' '259' '261' '262' '263' '264'\n",
      " '265' '266' '267' '268' '269' '271' '272' '273' '274' '275' '276' '277'\n",
      " '278' '279' '280' '281' '282' '283' '284' '285' '287' '288' '289' '290'\n",
      " '291' '292' '293' '294' '295' '296' '298' '299']\n"
     ]
    }
   ],
   "source": [
    "features_bool = np.array(rfe1.support_)\n",
    "features = np.array(X.columns)\n",
    "result = features[features_bool]\n",
    "print(result)\n",
    "X = X[result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 275)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the model (using the default parameters)\n",
    "log_clf = LogisticRegression()\n",
    "# fit the model with data\n",
    "log_clf.fit(X_train,y_train)\n",
    "y_pred=log_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17, 11],\n",
       "       [13, 34]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n",
      "Precision: 0.7555555555555555\n",
      "Recall: 0.723404255319149\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "forest_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9, 19],\n",
       "       [11, 36]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Precision: 0.6545454545454545\n",
      "Recall: 0.7659574468085106\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf = SVC(kernel='linear', C = 100)  \n",
    "svc_clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = svc_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15, 13],\n",
       "       [ 5, 42]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "Precision: 0.7636363636363637\n",
      "Recall: 0.8936170212765957\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.03, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=42,\n",
       "   selection='random', tol=0.01, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_clf = Lasso(alpha=0.03, tol=0.01, selection='random', random_state=42)\n",
    "#lasso_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits = 10\n",
    "# folds = RepeatedStratifiedKFold(n_splits=splits, n_repeats=20, random_state=42)\n",
    "# oof_preds = np.zeros(X_train.shape[0])\n",
    "# sub_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "# for fold_, (trn_, val_) in enumerate(folds.split(X_train, y_train)):\n",
    "#     trn_x, trn_y = X_train.iloc[trn_], y_train[trn_]\n",
    "#     val_x, val_y = X_train.iloc[val_], y_train[val_]\n",
    "\n",
    "# model = RFECV(lasso_clf, step=1, cv=(splits - 1))\n",
    "# model.fit(X_train, y_train)\n",
    "# oof_preds[val_] = model.predict(val_x).clip(0, 1)\n",
    "# sub_preds += model.predict(X_test).clip(0, 1) / splits / 20 #folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "# print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "# print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID search for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'bootstrap': [True], 'max_depth': [80, 90, 100, 110], 'max_features': [2, 3], 'min_samples_leaf': [3, 4, 5], 'min_samples_split': [8, 10, 12], 'n_estimators': [100, 200, 300, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_1 = { 'bootstrap': [True],\n",
    "           'max_depth': [80, 90, 100, 110],\n",
    "        'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "   'min_samples_split': [8, 10, 12],\n",
    "        'n_estimators': [100, 200, 300, 1000]\n",
    "           }\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(rf, param_grid = grid_1, n_jobs=-1, cv=5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6514285714285715"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 80,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfclf1 = RandomForestClassifier(bootstrap= True, max_depth= 80, max_features= 3, min_samples_leaf= 3, min_samples_split= 8,\n",
    "                               n_estimators= 100)\n",
    "rfclf1.fit(X_train, y_train)\n",
    "y_pred = rfclf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64\n",
      "Precision: 0.6351351351351351\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = ensemble.GradientBoostingClassifier()\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred = tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9, 19],\n",
       "       [ 3, 44]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7066666666666667\n",
      "Precision: 0.6984126984126984\n",
      "Recall: 0.9361702127659575\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = []\n",
    "#estimators.append(('logistic', log_clf))\n",
    "#estimators.append(('gbm', tree_clf))\n",
    "estimators.append(('randomforest', rfclf1))\n",
    "estimators.append(('svm', svc_clf))\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mruna\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\mruna\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\mruna\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\mruna\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\mruna\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\mruna\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\mruna\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7521421370967742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mruna\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.78125   , 0.6875    , 0.74193548, 0.90322581, 0.64516129,\n",
       "       0.70967742, 0.77419355, 0.77419355])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = cross_val_score(ensemble, X, y, cv=8)\n",
    "print(results.mean())\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [0.76 0.6  0.68 0.68 0.6  0.8  0.76 0.68 0.64 0.68]\n"
     ]
    }
   ],
   "source": [
    "# Perform 6-fold cross validation\n",
    "#logreg\n",
    "scores = cross_val_score(tree_clf, X, y, cv=10)\n",
    "print(\"Cross-validated scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
